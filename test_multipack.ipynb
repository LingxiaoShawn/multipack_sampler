{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from multipack_sampler import MultipackDistributedBatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterleavedSampler:\n",
    "    def __init__(self, lengths: np.ndarray, batch_size: int, num_replicas: int, rank: int, seed: int = 0):\n",
    "        self.seed = seed\n",
    "\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "    def num_batches(self):\n",
    "        return len(self.lengths) // (self.num_replicas * self.batch_size)\n",
    "    \n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = np.random.default_rng(seed=self.seed + self.epoch).permutation(len(self.lengths))\n",
    "\n",
    "        lengths = self.lengths[indices]\n",
    "        overall_batch_size = self.batch_size * self.num_replicas\n",
    "        for index in range(0, len(lengths), overall_batch_size):\n",
    "            batch = lengths[index: index + overall_batch_size]\n",
    "            if len(batch) < self.num_replicas:\n",
    "                break\n",
    "\n",
    "            result = indices[index + np.argsort(batch)]\n",
    "            yield result[self.rank + np.arange(self.batch_size) * self.num_replicas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler Multipack:\n",
      "[36, 36, 36, 36, 36, 36, 36, 36]\n",
      "Overall Efficiency: 0.9963896327548557\n",
      "Sampler Interleaved:\n",
      "[48, 48, 48, 48, 48, 48, 48, 48]\n",
      "Overall Efficiency: 0.756684939066569\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"testdata.json\"\n",
    "BATCH_SIZE = 16\n",
    "CTX_LEN = 2048\n",
    "NUM_GPUS = 8\n",
    "EPOCHS = 10\n",
    "\n",
    "SAMPLERS = {\n",
    "    \"Multipack\": lambda lengths, rank: MultipackDistributedBatchSampler(lengths=lengths, batch_max_length=BATCH_SIZE * CTX_LEN, num_replicas=NUM_GPUS, rank=rank),\n",
    "    \"Interleaved\": lambda lengths, rank: InterleavedSampler(lengths=lengths, batch_size=BATCH_SIZE, num_replicas=NUM_GPUS, rank=rank),\n",
    "}\n",
    "\n",
    "# Load testdata\n",
    "with open(DATASET, \"r\") as f:\n",
    "    lengths = np.array(json.load(f))\n",
    "\n",
    "# test sampler correctness & efficiency\n",
    "for sampler_name, sampler_fn in SAMPLERS.items():\n",
    "    print(f\"Sampler {sampler_name}:\")\n",
    "\n",
    "    tot_len = 0\n",
    "    tot_batches = 0\n",
    "\n",
    "    samplers = [sampler_fn(lengths=lengths, rank=rank) for rank in range(NUM_GPUS)]\n",
    "    print([sampler.num_batches() for sampler in samplers])\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        batches = []\n",
    "        tot_length = [[] for _ in range(NUM_GPUS)]\n",
    "\n",
    "        for rank, sampler in enumerate(samplers):\n",
    "            sampler.set_epoch(epoch)\n",
    "            for batch in sampler:\n",
    "                batches.extend(batch)\n",
    "\n",
    "                # Check constraints\n",
    "                overall_len = sum([lengths[x] for x in batch])\n",
    "                assert overall_len <= BATCH_SIZE * CTX_LEN\n",
    "\n",
    "                # Add stats\n",
    "                tot_len += overall_len\n",
    "                tot_batches += 1\n",
    "\n",
    "        # Check overall unique\n",
    "        batches.sort()\n",
    "        assert batches == list(set(batches))  # Unique\n",
    "\n",
    "    # Check efficiency\n",
    "    print(f\"Overall Efficiency: {tot_len / (tot_batches * CTX_LEN * BATCH_SIZE)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
