{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from multipack_sampler import MultipackDistributedBatchSampler\n",
    "from multipack_sampler_linear import MultipackDistributedBatchSampler_LinearAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterleavedSampler:\n",
    "    def __init__(self, lengths: np.ndarray, batch_size: int, num_replicas: int, rank: int, seed: int = 0):\n",
    "        self.seed = seed\n",
    "\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "    def num_batches(self):\n",
    "        return len(self.lengths) // (self.num_replicas * self.batch_size)\n",
    "    \n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = np.random.default_rng(seed=self.seed + self.epoch).permutation(len(self.lengths))\n",
    "\n",
    "        lengths = self.lengths[indices]\n",
    "        overall_batch_size = self.batch_size * self.num_replicas\n",
    "        for index in range(0, len(lengths), overall_batch_size):\n",
    "            batch = lengths[index: index + overall_batch_size]\n",
    "            if len(batch) < self.num_replicas:\n",
    "                break\n",
    "\n",
    "            result = indices[index + np.argsort(batch)]\n",
    "            yield result[self.rank + np.arange(self.batch_size) * self.num_replicas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler Multipack QuadraticAttention:\n",
      "Batch count for ranks: [37, 37, 37, 37, 37, 37, 37, 37]\n",
      "Packing Time: 20ms\n",
      "\n",
      "L^2 lag avg: 438 max: 717\n",
      "Efficiency: 99.70%\n",
      "Utilization: 98.16%\n",
      "==========\n",
      "\n",
      "Sampler Multipack LinearAttention:\n",
      "Batch count for ranks: [36, 36, 36, 36, 36, 36, 36, 36]\n",
      "Packing Time: 19ms\n",
      "\n",
      "L^2 lag avg: 6500 max: 6761\n",
      "Efficiency: 99.64%\n",
      "Utilization: 99.64%\n",
      "==========\n",
      "\n",
      "Sampler Interleaved:\n",
      "Batch count for ranks: [48, 48, 48, 48, 48, 48, 48, 48]\n",
      "Packing Time: 0ms\n",
      "\n",
      "L^2 lag avg: 1914 max: 2000\n",
      "Efficiency: 96.79%\n",
      "Utilization: 75.67%\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"testdata.json\"\n",
    "BATCH_SIZE = 16\n",
    "CTX_LEN = 2048\n",
    "NUM_GPUS = 8\n",
    "EPOCHS = 10\n",
    "\n",
    "SAMPLERS = {\n",
    "    \"Multipack QuadraticAttention\": lambda lengths, rank: MultipackDistributedBatchSampler(lengths=lengths, batch_max_length=BATCH_SIZE * CTX_LEN, num_replicas=NUM_GPUS, rank=rank),\n",
    "    \"Multipack LinearAttention\": lambda lengths, rank: MultipackDistributedBatchSampler_LinearAttention(lengths=lengths, batch_max_length=BATCH_SIZE * CTX_LEN, num_replicas=NUM_GPUS, rank=rank),\n",
    "\n",
    "    \"Interleaved\": lambda lengths, rank: InterleavedSampler(lengths=lengths, batch_size=BATCH_SIZE, num_replicas=NUM_GPUS, rank=rank),\n",
    "}\n",
    "\n",
    "# Load testdata\n",
    "with open(DATASET, \"r\") as f:\n",
    "    lengths = np.array(json.load(f))\n",
    "\n",
    "# test sampler correctness & efficiency\n",
    "for sampler_name, sampler_fn in SAMPLERS.items():\n",
    "    print(f\"Sampler {sampler_name}:\")\n",
    "\n",
    "    tot_len = 0\n",
    "    tot_maxlen = 0\n",
    "    tot_batches = 0\n",
    "    avg_sql2lag = 0\n",
    "    max_sql2lag = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    samplers = [sampler_fn(lengths=lengths, rank=rank) for rank in range(NUM_GPUS)]\n",
    "    print(\"Batch count for ranks:\", [sampler.num_batches() for sampler in samplers])\n",
    "    print(f\"Packing Time: {(time.time() - start_time) * 1000:.0f}ms\")\n",
    "    print(\"\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        batches = []\n",
    "        sqlen = [[] for _ in range(NUM_GPUS)]\n",
    "        olen = [[] for _ in range(NUM_GPUS)]\n",
    "\n",
    "        for rank, sampler in enumerate(samplers):\n",
    "            sampler.set_epoch(epoch)\n",
    "\n",
    "            for batch in sampler:\n",
    "                batches.extend(batch)\n",
    "\n",
    "                # Check constraints\n",
    "                overall_len = sum([lengths[x] for x in batch])\n",
    "                square_len = sum([lengths[x] ** 2 for x in batch])\n",
    "                assert overall_len <= BATCH_SIZE * CTX_LEN\n",
    "\n",
    "                # Add stats\n",
    "                tot_len += overall_len\n",
    "                tot_batches += 1\n",
    "\n",
    "                # square len\n",
    "                sqlen[rank].append(square_len)\n",
    "                olen[rank].append(overall_len)\n",
    "\n",
    "        tot_maxlen += np.sum(np.max(olen, axis=0))\n",
    "\n",
    "        sqlen = np.array(sqlen)\n",
    "        sqlag = np.max(sqlen, axis=0) - np.min(sqlen, axis=0)\n",
    "\n",
    "        avg_sql2lag += np.sqrt(np.mean(sqlag))\n",
    "        max_sql2lag += np.sqrt(np.max(sqlag))\n",
    "\n",
    "        # Check overall unique\n",
    "        batches.sort()\n",
    "        assert batches == list(set(batches))  # Unique\n",
    "\n",
    "    # Check efficiency\n",
    "    print(f\"L^2 lag avg: {avg_sql2lag / EPOCHS:.0f} max: {max_sql2lag / EPOCHS:.0f}\")\n",
    "    print(f\"Efficiency: {tot_len / (tot_batches * CTX_LEN * BATCH_SIZE) * 100:.2f}%\")\n",
    "    print(f\"Utilization: {tot_len / (tot_maxlen * NUM_GPUS) * 100:.2f}%\")\n",
    "    print(\"==========\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
